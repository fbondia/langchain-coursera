# üß™ Laborat√≥rio LangChain com seus pr√≥prios dados

Este reposit√≥rio re√∫ne anota√ß√µes e c√≥digos experimentais baseados no curso ["LangChain: Chat with Your Data"](https://learn.deeplearning.ai/courses/langchain-chat-with-your-data/lesson/snupv/introduction), com foco em compreender e testar as etapas principais de processamento de documentos: **LOAD ‚Üí SPLIT ‚Üí EMBED ‚Üí RETRIEVE**.


## Baseado no curso em:

https://learn.deeplearning.ai/courses/langchain-chat-with-your-data/lesson/snupv/introduction


## üìÑ Documento usado nos testes

O PDF referenciado em alguns exemplos de c√≥digo vem do curso de Stanford. Para baix√°-lo, execute:

```bash
curl -O https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf
```

Salve em: **./docs/cs229_lectures/**

## Recomend√°vel criar o ambiente com virtualenv

```
virtualenv env
source env/bin/activate
```

## Depend√™ncias

```
pip install langchain pypdf yt_dlp pydub dotenv openai langchain-community beautifulsoup4 tiktoken
```

## O processo com o LangChain ocorre nas etapas LOAD, SPLIT, EMBED, RETRIEVE

### 1 - LOAD

Uma parte importante do LangChain s√£o seus DocumentLoaders, que podem carregar:

**Dados p√∫blicos**
- dados n√£o estruturados: youtube, wikipedia, twiter etc.
- dados estruturados: datasets, apis, csv etc.

**Dados privados**
- dados n√£o estruturados: power-point, notion, whatsapp etc.
- dados estruturados: pandas, excel, stripe, elastic etc.


#### 2 - SPLIT
Ap√≥s o carregamento, os documentos precisam ser divididos em peda√ßos menores (chunks) para que possam ser processados e indexados eficientemente ‚Äî especialmente em sistemas de busca vetorial.

##### Desafios do split
Dividir um texto apenas por n√∫mero de caracteres pode cortar frases ou ideias importantes no meio, dificultando a recupera√ß√£o de informa√ß√µes relevantes.

##### Estrat√©gias para preservar contexto
Uma pr√°tica comum √© usar overlapping entre chunks:

Por exemplo, se o chunk A vai de 0 a 500 tokens, o chunk B pode come√ßar no token 400 e ir at√© o 900, criando uma sobreposi√ß√£o de 100 tokens. Isso ajuda a manter o contexto fluido entre trechos consecutivos.


##### Principais Tipos de Text Splitters no LangChain

Os Text Splitters s√£o respons√°veis por dividir documentos em peda√ßos menores (**chunks**) para facilitar o processamento, indexa√ß√£o e busca. A escolha do splitter certo pode impactar diretamente a qualidade das respostas em sistemas baseados em RAG (retrieval-augmented generation).

###### CharacterTextSplitter

Divide o texto com base em um n√∫mero fixo de caracteres, sem considerar a estrutura sem√¢ntica. √â simples e r√°pido, mas pode cortar ideias no meio se n√£o for bem parametrizado.

```python
from langchain.text_splitter import CharacterTextSplitter
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)
```

###### MarkdownHeaderTextSplitter
Divide documentos com base na hierarquia de cabe√ßalhos Markdown (#, ##, ### etc.), preservando a estrutura do conte√∫do. Ideal para documenta√ß√£o t√©cnica.

```
from langchain.text_splitter import MarkdownHeaderTextSplitter
```

###### TokenTextSplitter
Usa contagem de tokens em vez de caracteres. √â √∫til para evitar que o chunk ultrapasse o limite de tokens de modelos como GPT.

```
from langchain.text_splitter import TokenTextSplitter
```

###### SentenceTransformersTokenTextSplitter
Usa embeddings para identificar pontos de corte sem√¢ntico entre senten√ßas, mantendo a coes√£o do texto. Requer a instala√ß√£o do sentence-transformers.

```
from langchain.text_splitter import SentenceTransformersTokenTextSplitter
```

###### RecursiveCharacterTextSplitter
O splitter mais recomendado na maioria dos casos. Tenta dividir primeiro por se√ß√µes maiores (como par√°grafos, frases) e vai recursivamente at√© atingir o tamanho ideal. Preserva bem o contexto.

```
from langchain.text_splitter import RecursiveCharacterTextSplitter
```

###### NLTKTextSplitter
Baseado na biblioteca NLTK, divide textos em senten√ßas respeitando a pontua√ß√£o e a gram√°tica. Requer o nltk instalado e seus recursos baixados.

```
from langchain.text_splitter import NLTKTextSplitter
```

###### SpacyTextSplitter
Semelhante ao NLTKTextSplitter, mas usa o spaCy para an√°lise sint√°tica mais precisa. Pode reconhecer entidades, frases nominais, etc.

```
from langchain.text_splitter import SpacyTextSplitter
```

###### Language (Code Splitter)

Pensado para c√≥digo-fonte. Usa a linguagem de programa√ß√£o como base para dividir trechos de c√≥digo por classes, fun√ß√µes ou blocos. Muito √∫til em agentes que lidam com bases de c√≥digo.

```
from langchain.text_splitter import Language
```


##### Informa√ß√µes interessantes
- Os chunks armazenam metadados relacionados a sua fonte - um chunk separado a partir de um pdf pode ter o nome do arquivo e a p√°gina em que foi produzido; um markdown pode ter a estrutura de cabe√ßalhos na qual se originou; etc


### 3 - EMBED
